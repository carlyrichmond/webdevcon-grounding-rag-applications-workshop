# Lab 2.4: Interaction with Multiple Tools

Now that we have written our first tool, let's see how LLMs may interact and handle calling multiple tools. In this exercise we shall add a tool to get data from the UK Government's FCDO office to give guidance on travel locations.

## Steps

1. Write a new tool `fcdoGuidance` to call the [GOV.UK Content API](https://content-api.publishing.service.gov.uk/reference.html#gov-uk-content-api) for a given location. Feel free to change this call to dummy data or use an alternative resource if you wish. This tool should reside in a new TypeScript file `/ai/fcdo.tool.ts`

```ts
import { tool as createTool } from 'ai';
import { z } from 'zod';

import { FCDOResponse } from '../model/fco.model';

export const fcdoTool = createTool({
  description: 
  'Display the FCDO guidance for a destination',
  parameters: z.object({
    country: z.string().describe('The country of the location to get the guidance for')
  }),
  execute: async function ({ country }) {
    const url = `https://www.gov.uk/api/content/foreign-travel-advice/${country.toLowerCase()}`;
    
    try {
      const response = await fetch(url, { headers: { 'Content-Type': 'application/json' } });
      const fcoResponse: FCDOResponse = await response.json();

      const alertStatus: string = fcoResponse.details.alert_status.length == 0 ? 'Unknown' : 
      fcoResponse.details.alert_status[0].replaceAll('_', ' ');

      return { 
        status: alertStatus, 
        url: fcoResponse.details?.document?.url
      };
    } catch(e) {
      console.error(e);
      return { 
        message: 'Unable to obtain FCDO information', 
        location: location
      };
    }
  }
});
```

2. Add the tool call to the `api/chat` request handler, located in `/api/chat/route.ts`:

```ts
import { createOllama } from 'ollama-ai-provider';
import { streamText } from 'ai';
import { NextResponse } from 'next/server';

import { weatherTool } from '@/app/ai/weather.tool';
import { fcdoTool } from '@/app/ai/fcdo.tool';

export const maxDuration = 30;

const ollama = createOllama({
  baseURL: 'http://localhost:11434/api', // Default
});

export const tools = {
  fcdoGuidance: fcdoTool,
  displayWeather: weatherTool
};

export async function POST(req: Request) {
  const { messages } = await req.json();

  try {
    const result = streamText({
      model: ollama('llama3.1'),
      system:
      "You are a helpful assistant that returns travel itineraries based on a location" + 
        "Use the current weather from the displayWeather tool to adjust the itinerary and give packing suggestions." +
        "If the FCDO tool warns against travel DO NOT generate an itinerary.",
      messages,
      maxSteps: 2,
      tools
    });

    return result.toDataStreamResponse();
  } catch (e) {
    console.error(e);
    return new NextResponse(
      "Unable to generate a plan. Please try again later!"
    );
  }
}
```

At this point, when asking to generate an itinerary, how does the inclusion of the new tool change the output? Try experimenting with different locations where FCDO advise or advise against travel.

3. While it may be impacting the itinerary, it would also be useful to show the guidance. Using the provided React component located in `/components/fcdo.tsx`, update your `page.tsx` to included the output of the weather tool in the UI (hint, you'll need to amend the tool result condition!):

```tsx
'use client';

import { useChat } from '@ai-sdk/react';
import Image from 'next/image';
import { Converter } from 'showdown';

import Spinner from './components/spinner';
import { Weather } from './components/weather';
import { FCDOGuidance } from './components/fcdo';

import pending from '../../public/multi-cloud.svg';
import pin from '../../public/world-pin.svg';

export default function Chat() {
  /* useChat hook helps us handle the input, resulting messages, and also handle the loading and error states for a better user experience */
  const { messages, input, handleInputChange, handleSubmit, isLoading, stop, error, reload } = useChat();

  return (
    <div className="chat__form">
      <div className="chat__messages">
        {
          /* Display all user messages and assistant responses */
          messages.map(m => (
            <div key={m.id} className="message">
              <div>
                { /* Messages with the role of *assistant* denote responses from the LLM */}
                <div className="role">{m.role === "assistant" ? "Sorley" : "Me"}</div>
                { /* Tool handling */}
                <div className="tools__summary">
                  {
                    m.parts.map(part => {
                      if (part.type === 'tool-invocation') {
                        const { toolName, toolCallId, state } = part.toolInvocation;

                        if (state === 'result') {
                          if (toolName === 'displayWeather') {
                            { /* Show weather results */}
                            const { result } = part.toolInvocation;
                            return (
                              <div key={toolCallId}>
                                <Weather {...result} />
                              </div>
                            )
                           } else if (toolName === 'fcdoGuidance') {
                            { /* Show FCDO travel guidance */}
                            const { result } = part.toolInvocation;
                            return (
                              <div key={toolCallId}>
                                <FCDOGuidance {...result} />
                              </div>
                            );
                          }
                        } else {
                          return (
                            <div key={toolCallId}>
                              {toolName === 'displayWeather' ? (
                                <div className="weather__tool">
                                  <Image src={pending} width={80} height={80} alt="Placeholder Weather"/>
                                  <p className="loading__weather__message">Loading weather...</p>
                                </div>
                              ) : null}

                              {toolName === 'fcdoGuidance' ? (
                                <div className="fcdo__tool">
                                  <Image src={pin} width={80} height={80} alt="Placeholder FCDO Advice"/>
                                  <p className="loading__fcdo__message">Loading FCDO advice...</p>
                                </div>
                              ) : null}
                            </div>
                          );
                        }

                        
                      }
                    })}
                </div>
                <div className="itinerary__div">{m.content}</div>
              </div>
            </div>
          ))}
      </div>

      {
        isLoading && (
          <div className="spinner__container">
            <Spinner />
            <button id="stop__button" type="button" onClick={() => stop()}>
              Stop
            </button>
          </div>
        )}

      {
        error && (
          <>
            <div className="error__container">Unable to generate a plan. Please try again later!</div>
            <button id="retry__button" type="button" onClick={() => reload()}>
              Retry
            </button>
          </>
        )}

      <form onSubmit={handleSubmit}>
        <input
          className="search-box__input"
          value={input}
          placeholder="Where would you like to go?"
          onChange={handleInputChange}
          disabled={error != null}/>
      </form>
    </div>
  );
}
```

4. Try requesting itineraries for a mixture of locations, and seeing the output. What do you see? Does changing the prompt impact which tools are called for these inputs?

# Expected Result

If all goes well, you'll be able to see FCDO guidance. However, what you may see if that both tools are not present, and that the LLM is choosing one tool to call at a time. Why do you think that is?